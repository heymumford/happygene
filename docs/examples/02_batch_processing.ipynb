{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing & Statistics\n",
    "\n",
    "Run multiple simulations and analyze aggregate statistics.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to run 100+ simulations efficiently\n",
    "- How to compute mean, std, min, max statistics\n",
    "- How to save and load results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine.simulator.batch import BatchSimulator\n",
    "from engine.domain.config import HappyGeneConfig, DamageProfile, KineticsConfig\n",
    "import statistics\n",
    "\n",
    "# Configure simulation\n",
    "damage_profile = DamageProfile(dose_gy=3.0, population_size=1000)\n",
    "kinetics = KineticsConfig(\n",
    "    recognition_rate=0.1,\n",
    "    repair_rate=0.05,\n",
    "    misrepair_rate=0.01,\n",
    "    recovery_rate=0.02\n",
    ")\n",
    "config = HappyGeneConfig(damage_profile=damage_profile, kinetics=kinetics)\n",
    "\n",
    "print(\"✓ Configuration ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Batch Simulations\n",
    "\n",
    "Execute 100 independent simulations with the same configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch simulator\n",
    "batch = BatchSimulator(config)\n",
    "\n",
    "# Run 100 simulations\n",
    "print(\"Running 100 simulations...\")\n",
    "results = batch.run_batch(num_runs=100)\n",
    "\n",
    "print(f\"✓ Complete! Got {len(results)} results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute aggregate statistics\n",
    "stats = BatchSimulator.compute_statistics(results)\n",
    "\n",
    "print(\"\\n=== Repair Time Statistics ===\")\n",
    "print(f\"Mean:   {stats['mean_repair_time']:.4f} seconds\")\n",
    "print(f\"Std:    {stats['std_repair_time']:.4f} seconds\")\n",
    "print(f\"Min:    {stats['min_repair_time']:.4f} seconds\")\n",
    "print(f\"Max:    {stats['max_repair_time']:.4f} seconds\")\n",
    "\n",
    "print(\"\\n=== Repair Count Statistics ===\")\n",
    "print(f\"Mean:   {stats['mean_repair_count']:.1f} lesions\")\n",
    "print(f\"Std:    {stats['std_repair_count']:.1f} lesions\")\n",
    "print(f\"Runs:   {int(stats['num_runs'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Individual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show first 5 results\n",
    "print(\"First 5 runs:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Run':<4} {'Time(s)':<10} {'Repairs':<10} {'Status':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, result in enumerate(results[:5]):\n",
    "    print(f\"{result['run_id']:<4} {result['completion_time']:<10.4f} {result['final_repair_count']:<10} {result['status']:<10}\")\n",
    "\n",
    "# Find extremes\n",
    "fastest = min(results, key=lambda r: r['completion_time'])\n",
    "slowest = max(results, key=lambda r: r['completion_time'])\n",
    "most_repaired = max(results, key=lambda r: r['final_repair_count'])\n",
    "least_repaired = min(results, key=lambda r: r['final_repair_count'])\n",
    "\n",
    "print(\"\\nExtremes:\")\n",
    "print(f\"  Fastest: {fastest['completion_time']:.4f}s (run {fastest['run_id']})\")\n",
    "print(f\"  Slowest: {slowest['completion_time']:.4f}s (run {slowest['run_id']})\")\n",
    "print(f\"  Most repairs: {most_repaired['final_repair_count']} (run {most_repaired['run_id']})\")\n",
    "print(f\"  Least repairs: {least_repaired['final_repair_count']} (run {least_repaired['run_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Create temp file for demo\n",
    "output_file = Path(tempfile.gettempdir()) / \"batch_results.h5\"\n",
    "\n",
    "# Save results\n",
    "batch.save_results(results, output_file)\n",
    "print(f\"✓ Saved to {output_file}\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved results\n",
    "loaded = BatchSimulator.load_results(output_file)\n",
    "print(f\"✓ Loaded {len(loaded)} results\")\n",
    "print(f\"  First run ID: {loaded[0]['run_id']}\")\n",
    "print(f\"  Last run ID: {loaded[-1]['run_id']}\")\n",
    "\n",
    "# Verify statistics match\n",
    "stats_loaded = BatchSimulator.compute_statistics(loaded)\n",
    "print(f\"\\n  Mean repairs (original): {stats['mean_repair_count']:.1f}\")\n",
    "print(f\"  Mean repairs (loaded):   {stats_loaded['mean_repair_count']:.1f}\")\n",
    "print(f\"  ✓ Match: {abs(stats['mean_repair_count'] - stats_loaded['mean_repair_count']) < 0.01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract repair counts\n",
    "repair_counts = [r['final_repair_count'] for r in results]\n",
    "\n",
    "# Calculate additional statistics\n",
    "median = statistics.median(repair_counts)\n",
    "cv = stats['std_repair_count'] / stats['mean_repair_count']  # Coefficient of variation\n",
    "\n",
    "print(\"\\nAdditional Statistics:\")\n",
    "print(f\"  Median repairs: {median:.0f}\")\n",
    "print(f\"  Coefficient of variation: {cv:.3f}\")\n",
    "print(f\"  Range: {min(repair_counts)} - {max(repair_counts)}\")\n",
    "print(f\"  95% CI: [{stats['mean_repair_count'] - 1.96*stats['std_repair_count']:.1f}, {stats['mean_repair_count'] + 1.96*stats['std_repair_count']:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Visualize results**: See notebook 03 for interactive dashboards\n",
    "2. **Parameter sensitivity**: See notebook 05 to understand how parameters affect outcomes\n",
    "3. **Export to COPASI**: See notebook 04 for SBML workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
